{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a239eea-e414-412d-9242-d7316e9cc18d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a7fcd7-eb6b-4ee8-8f57-ff5a443c78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q torch==1.13.1 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6eb2fe-f515-471e-8ae3-1aae649d697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c866a9c-6192-4cf1-b8e7-1b96c98953f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1961ba0b-d202-4477-8004-63b1c5e5ca34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 15 13:51:38 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   31C    P8    22W / 300W |      1MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a20d7-05ea-4951-a079-08c8b8a71940",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16825bfc-8853-445c-9e6c-53395bea41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "import subprocess\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, StratifiedGroupKFold, GroupKFold\n",
    "from sklearn.metrics import f1_score, mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f6e65d9-657c-4b4d-a20c-ccd0dc3f5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b9b22b-0a41-44b0-beec-e050afbeaa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR\n",
    "from torch import LongTensor\n",
    "from torch import nn, optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee4c3033-b975-4aac-bc6b-24346ea9c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "# from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm, trange\n",
    "import datasets\n",
    "from datasets import load_dataset, DatasetDict, Dataset as HFDataset\n",
    "from datasets import concatenate_datasets, interleave_datasets\n",
    "from datasets import ClassLabel, load_metric\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_FOR_MASKED_LM_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563effdb-c378-45ba-8f7e-8d7cc8bf8b08",
   "metadata": {},
   "source": [
    "# Envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db742f8-2be3-47d5-bd7b-82629ce77866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_warnings(strict=False):\n",
    "\twarnings.simplefilter('ignore')\n",
    "\tif strict:\n",
    "\t\tlogging.disable(logging.WARNING)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "\trandom.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c01b0cb9-83b7-46c0-8383-c9384772e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "disable_warnings()\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7fe6b-98d6-4d75-9912-bf1bf44b6643",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe357fad-adaf-4b32-8c8a-3bfba4d57170",
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = '../lacuna_pos_ner/language_corpus/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78f54e1e-1c04-40a8-b297-d7bf05d901d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data_ner(data_path, lang, split='train'):\n",
    "    language = lang.split('_')[0]\n",
    "    \n",
    "    try:\n",
    "        with open(f'{data_path}{lang}/{split}.txt', 'r') as f:\n",
    "            sentences = []\n",
    "            \n",
    "            for line in f.readlines():\n",
    "                line = line.strip().rstrip()\n",
    "                line = re.sub('.$', ' .', line)\n",
    "                line = line.replace('. ', ' . ')\n",
    "                for punct in list(\"!#$%&()*+,/:;<=>?@[]^_{|}~\"):\n",
    "                    line = line.replace(punct, f' {punct}')\n",
    "                line = line.strip().rstrip()\n",
    "                \n",
    "                if len(line):\n",
    "                    sentences.append(line)\n",
    "\n",
    "        data = pd.DataFrame({\n",
    "            'Word': sentences,\n",
    "            'Language': language.split('_')[0]\n",
    "        })\n",
    "        data['family'] = language\n",
    "        data['region'] = language\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33c772cf-7bd1-41d0-b4aa-b2f8b926c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(string)\n",
    "# list(\"!#$%&\\()*+,/:;<=>?@[\\\\]^_{|}~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd40436e-a4f4-4823-99b3-8ff6c05636de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Language</th>\n",
       "      <th>family</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jalup Ker Ruto nobedo e nyasi achiel kod Ker U...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jalup Ker , William Ruto  mosebedo kabare e ny...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nyasino timore Mei tarik 27 e Od Piny Owacho ,...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ma en kinde mar adek ma jotelo ariyogo obedo e...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chieng' Tich Ariyo , Dan Maanzo , ma  en jakon...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Word Language family region\n",
       "0  Jalup Ker Ruto nobedo e nyasi achiel kod Ker U...      luo    luo    luo\n",
       "1  Jalup Ker , William Ruto  mosebedo kabare e ny...      luo    luo    luo\n",
       "2  Nyasino timore Mei tarik 27 e Od Piny Owacho ,...      luo    luo    luo\n",
       "3  Ma en kinde mar adek ma jotelo ariyogo obedo e...      luo    luo    luo\n",
       "4  Chieng' Tich Ariyo , Dan Maanzo , ma  en jakon...      luo    luo    luo"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Language</th>\n",
       "      <th>family</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12175</th>\n",
       "      <td>Bagaka ba Bundesliga ba ba tshwanang le motshw...</td>\n",
       "      <td>tsn</td>\n",
       "      <td>tsn</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12176</th>\n",
       "      <td>Re tshwanetse go diragatsa togamaano ya rona ,...</td>\n",
       "      <td>tsn</td>\n",
       "      <td>tsn</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>Hungary le Portugal di tshamekile mengwe ya me...</td>\n",
       "      <td>tsn</td>\n",
       "      <td>tsn</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12178</th>\n",
       "      <td>Hungary e ne e itlhomile kwa pele mo setlhophe...</td>\n",
       "      <td>tsn</td>\n",
       "      <td>tsn</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12179</th>\n",
       "      <td>Ditlhopha di le robedi di tlaa tsenela dikgais...</td>\n",
       "      <td>tsn</td>\n",
       "      <td>tsn</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Word Language family  \\\n",
       "12175  Bagaka ba Bundesliga ba ba tshwanang le motshw...      tsn    tsn   \n",
       "12176  Re tshwanetse go diragatsa togamaano ya rona ,...      tsn    tsn   \n",
       "12177  Hungary le Portugal di tshamekile mengwe ya me...      tsn    tsn   \n",
       "12178  Hungary e ne e itlhomile kwa pele mo setlhophe...      tsn    tsn   \n",
       "12179  Ditlhopha di le robedi di tlaa tsenela dikgais...      tsn    tsn   \n",
       "\n",
       "      region  \n",
       "12175    tsn  \n",
       "12176    tsn  \n",
       "12177    tsn  \n",
       "12178    tsn  \n",
       "12179    tsn  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.concat([\n",
    "    load_test_data_ner(path, 'luo', 'luo'),\n",
    "    load_test_data_ner(path, 'tsn', 'tsn'),\n",
    "    load_test_data_ner(path, 'tsn', 'tsn2'),\n",
    "]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "display(data.head())\n",
    "display(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de588c-aabf-4134-b3a3-c208e25b642b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8677ddf8-cd35-411b-bb67-397c2f501348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Language</th>\n",
       "      <th>family</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jalup Ker Ruto nobedo e nyasi achiel kod Ker U...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jalup Ker , William Ruto  mosebedo kabare e ny...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nyasino timore Mei tarik 27 e Od Piny Owacho ,...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ma en kinde mar adek ma jotelo ariyogo obedo e...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chieng' Tich Ariyo , Dan Maanzo , ma  en jakon...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Word Language family region\n",
       "0  Jalup Ker Ruto nobedo e nyasi achiel kod Ker U...      luo    luo    luo\n",
       "1  Jalup Ker , William Ruto  mosebedo kabare e ny...      luo    luo    luo\n",
       "2  Nyasino timore Mei tarik 27 e Od Piny Owacho ,...      luo    luo    luo\n",
       "3  Ma en kinde mar adek ma jotelo ariyogo obedo e...      luo    luo    luo\n",
       "4  Chieng' Tich Ariyo , Dan Maanzo , ma  en jakon...      luo    luo    luo"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4e4278d-e53b-4675-a97f-1643fac183bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_column_name = 'Word'\n",
    "label_column_name = 'Pos'\n",
    "num_labels = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "653024f4-d2fd-40b7-9a77-a67b0c1ff3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = {0: 'ADJ',\n",
    " 1: 'ADP',\n",
    " 2: 'ADV',\n",
    " 3: 'AUX',\n",
    " 4: 'CCONJ',\n",
    " 5: 'DET',\n",
    " 6: 'INTJ',\n",
    " 7: 'NOUN',\n",
    " 8: 'NUM',\n",
    " 9: 'PART',\n",
    " 10: 'PRON',\n",
    " 11: 'PROPN',\n",
    " 12: 'PUNCT',\n",
    " 13: 'SCONJ',\n",
    " 14: 'SYM',\n",
    " 15: 'VERB',\n",
    " 16: 'X',\n",
    " 17: 'NAW'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a78a58e7-22ef-49cc-857e-9811cf748e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_path,\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04218f8f-11fc-429e-b70e-c59931217409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9698fe8515584c77b3ca7e24ca0f91a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/714 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7592cb7ad043c7bc2c246c0ab0f2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b69c5d80b7b454aa7cecdb4863a7d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75611524f13d4c5498b16a052f7e8709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819f37ab578e4d608a9db5b9d4889300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'Davlan/afro-xlmr-large-75L'\n",
    "\n",
    "max_seq_length = 1024\n",
    "padding = False\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "tokenizer_name_or_path = model_name\n",
    "if config.model_type in {\"gpt2\", \"roberta\"}:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        tokenizer_name_or_path,\n",
    "        use_fast=True,\n",
    "        add_prefix_space=True,\n",
    "    )\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        tokenizer_name_or_path,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    \n",
    "data_collator = DataCollatorForTokenClassification(tokenizer, max_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54b5558a-0961-4dc5-ba9e-8f4103accfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(examples):\n",
    "    is_test = examples.get(label_column_name) is None\n",
    "    \n",
    "    for idx in range(len(examples[text_column_name])):\n",
    "        if not is_test:\n",
    "            examples[label_column_name][idx] = examples[label_column_name][idx].split(' ')\n",
    "        examples[text_column_name][idx] = examples[text_column_name][idx].split(' ')\n",
    "        \n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_column_name],\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        max_length=max_seq_length if not is_test else None,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "    \n",
    "    if not is_test:\n",
    "        labels = []\n",
    "        for i, label in enumerate(examples[label_column_name]):\n",
    "            word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "            previous_word_idx = None\n",
    "            label_ids = []\n",
    "            for word_idx in word_ids:\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif word_idx != previous_word_idx:\n",
    "                    label_ids.append(label_to_id[label[word_idx]])\n",
    "                else:\n",
    "                    label_ids.append(label_to_id['NAW'])\n",
    "                previous_word_idx = word_idx\n",
    "\n",
    "            labels.append(label_ids)\n",
    "        tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00797992-b49d-47d1-bc47-6cbffc86ccf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ce7fecdfdd46dcbc139c5a4b0dc5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 12180\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = HFDataset.from_pandas(data).remove_columns(column_names=['Language', 'family', 'region'])\n",
    "test_dataset = test_dataset.map(\n",
    "    process_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=['Word'],\n",
    ")\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "36b42ed1-5e09-48fa-a5e0-4fd6b6a06459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x) for x in test_dataset['input_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c3ab5b5-1122-4b5a-bf90-b3c07e34c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_fold(fold):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'pos-tagging-ner/{model_name.replace(\"/\", \"-\")}/{fold}',\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        gradient_accumulation_steps=1,\n",
    "        fp16=True,\n",
    "        report_to='none'\n",
    "    )\n",
    "    \n",
    "    model_path = glob(f'./pos-tagging-ner/Davlan-afro-xlmr-large-75L-best/{fold}/checkpoint-*')[0]\n",
    "\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=test_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "    \n",
    "    test_pos_ids = trainer.predict(test_dataset)\n",
    "    \n",
    "    return test_pos_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65bf22a7-cfe7-454b-a739-20bfc29d1430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = []\n",
    "\n",
    "for fold in [1, 2, 3, 4]:\n",
    "    fold_pred = predict_for_fold(fold)\n",
    "    \n",
    "    all_preds.append(fold_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b5423319-fc1d-4e9c-ab53-0eb0122803dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12180, 287, 18)\n"
     ]
    }
   ],
   "source": [
    "test_pos_ids = np.mean([p.predictions for p in all_preds], axis=0)\n",
    "print(test_pos_ids.shape)\n",
    "test_pos_ids = test_pos_ids.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "45ce2daa-b304-4065-8ab6-40fe16f91f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pos = []\n",
    "for pos_ids, sentence in zip(test_pos_ids, data.Word.values):\n",
    "    length = len(sentence.split())\n",
    "    final_pos.append(\n",
    "        \" \".join(list(map(id_to_label.get, [x for x in pos_ids if x not in [-100, 17]]))[1:length+1])\n",
    "    )\n",
    "    \n",
    "    assert length == len(final_pos[-1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ab63a58c-f2ec-43d8-8f79-fbc90939c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Pos'] = final_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "55dd1deb-7091-4db3-8cf9-8cd0147a6346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Language</th>\n",
       "      <th>family</th>\n",
       "      <th>region</th>\n",
       "      <th>Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jalup Ker Ruto nobedo e nyasi achiel kod Ker U...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>NOUN PROPN PROPN VERB ADP NOUN NUM ADP PROPN P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jalup Ker , William Ruto  mosebedo kabare e ny...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>NOUN NOUN PUNCT PROPN PROPN VERB ADV ADP NOUN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nyasino timore Mei tarik 27 e Od Piny Owacho ,...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>NOUN VERB PROPN NOUN NUM ADP NOUN PROPN PROPN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ma en kinde mar adek ma jotelo ariyogo obedo e...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>PRON AUX NOUN ADP NUM DET NOUN NUM VERB ADP NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chieng' Tich Ariyo , Dan Maanzo , ma  en jakon...</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>luo</td>\n",
       "      <td>NOUN NOUN NUM PUNCT PROPN PROPN PUNCT PRON AUX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Word Language family region  \\\n",
       "0  Jalup Ker Ruto nobedo e nyasi achiel kod Ker U...      luo    luo    luo   \n",
       "1  Jalup Ker , William Ruto  mosebedo kabare e ny...      luo    luo    luo   \n",
       "2  Nyasino timore Mei tarik 27 e Od Piny Owacho ,...      luo    luo    luo   \n",
       "3  Ma en kinde mar adek ma jotelo ariyogo obedo e...      luo    luo    luo   \n",
       "4  Chieng' Tich Ariyo , Dan Maanzo , ma  en jakon...      luo    luo    luo   \n",
       "\n",
       "                                                 Pos  \n",
       "0  NOUN PROPN PROPN VERB ADP NOUN NUM ADP PROPN P...  \n",
       "1  NOUN NOUN PUNCT PROPN PROPN VERB ADV ADP NOUN ...  \n",
       "2  NOUN VERB PROPN NOUN NUM ADP NOUN PROPN PROPN ...  \n",
       "3  PRON AUX NOUN ADP NUM DET NOUN NUM VERB ADP NO...  \n",
       "4  NOUN NOUN NUM PUNCT PROPN PROPN PUNCT PRON AUX...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fd03bca7-647e-41ce-84c7-6ffbf1096b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(f'pseudos/pos-ner-{model_name.split(\"/\")[-1]}-best.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b6f72-85c4-4881-8319-c59d5dd08de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
